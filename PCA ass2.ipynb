{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d957e26-de76-4f6c-b76d-5fe588a03900",
   "metadata": {},
   "source": [
    "Q1. What is a projection and how is it used in PCA?\n",
    "Ans->Projection means that we use the axis proposed by the principal component to map the data to this new space.\n",
    "we can find the distance with the help of projection ,formula is proj(p1)(u)=p1.u/||u||,where ||u|| =1\n",
    "\n",
    "\n",
    "\n",
    "Q2. How does the optimization problem in PCA work, and what is it trying to achieve?\n",
    "Ans->formula is same as cost function,Goal is to achieve the best unit vector which capture max variance.\n",
    "\n",
    "\n",
    "\n",
    "Q3. What is the relationship between covariance matrices and PCA?\n",
    "Ans->PCA is simply described as “diagonalizing the covariance matrix”.\n",
    "It simply means that we need to find a non-trivial linear combination of our original variables such that the covariance matrix is diagonal.\n",
    "\n",
    "\n",
    "Q4. How does the choice of number of principal components impact the performance of PCA?\n",
    "Ans->In PCA, choose the smallest number of components that still capture most of the information in your data. A common approach is to pick enough components to cover about 95% of the total data variance.\n",
    "\n",
    "\n",
    "Q5. How can PCA be used in feature selection, and what are the benefits of using it for this purpose?\n",
    "Ans->In feature selection, PCA can be used to identify the most important variables in a dataset.\n",
    "\n",
    "\n",
    "Q6. What are some common applications of PCA in data science and machine learning?\n",
    "Ans->Principal Component Analysis (PCA) is one of the most commonly used unsupervised machine learning algorithms across a variety of applications: exploratory data analysis, dimensionality reduction, information compression, data de-noising, and plenty more.\n",
    "\n",
    "\n",
    "Q7. How does PCA handle data with high variance in some dimensions but low variance in others?\n",
    "Ans->PCA gives more weight to variables that have higher variances than variables with low variances, so it is important to normalize the data on the same scale to get a reasonable covariance. 4. Now, we will import PCA using sklearn and project our original data, which has 4 dimensions, into 2 dimensions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
